{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPiMzifICttYqXnQwuAO+5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ummaysumaiya0808/Simple_NLP-summarizer/blob/main/Text_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufK5ZlyBjLIf",
        "outputId": "2c65bbb7-e2c0-4f43-e828-c03c6e578042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "sHqsWdO2G81p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89847d79-0dda-422d-d51a-9acd472134c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "b072bakuCRhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the cosine similarity between two sentences\n",
        "def SimilarSentence(sent1, sent2, stopwords):\n",
        "    w1 = [w.lower() for w in sent1] # w for word.\n",
        "    w2 = [w.lower() for w in sent2]\n",
        "\n",
        "# Make a set of all words in both sentences, excluding stopwords\n",
        "    AllWords = list(set(w1 + w2))\n",
        "\n",
        "# Create vectors for both sentences\n",
        "    v1 = [0] * len(AllWords)\n",
        "    v2 = [0] * len(AllWords)\n",
        "\n",
        "# Count the vectors for each word\n",
        "    for w in w1:\n",
        "        if w not in stopwords:\n",
        "            v1[AllWords.index(w)] += 1\n",
        "\n",
        "    for w in w2:\n",
        "        if w not in stopwords:\n",
        "            v2[AllWords.index(w)] += 1\n",
        "\n",
        "# Calculating the cosine similarity\n",
        "    return 1 - cosine_distance(v1, v2)\n",
        "\n",
        "def build_simi_matrix(sentences, stopwords):  # Making a similarity matrix for all sentences\n",
        "    simi_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(len(sentences)):\n",
        "            if i != j:\n",
        "                simi_matrix[i][j] = SimilarSentence(sentences[i], sentences[j], stopwords)\n",
        "\n",
        "    return simi_matrix\n",
        "\n",
        "# Generating a summary from a text\n",
        "def GenSum(text_data, NumofSents):\n",
        "    sentences = nltk.sent_tokenize(text_data)\n",
        "    stop_words = stopwords.words('english')\n",
        "\n",
        "    simi_matrix = build_simi_matrix(sentences, stop_words) # Create a similarity matrix\n",
        "\n",
        "    SentenceRank = np.array(np.sum(simi_matrix, axis=1)) # Rank sentences based on similarity\n",
        "\n",
        "    IndexofRankedSent = [item[0] for item in sorted(enumerate(SentenceRank), key=lambda item: -item[1])] # Get the indexes of the top N sentences\n",
        "\n",
        "    SumofSents = [sentences[i] for i in IndexofRankedSent[:NumofSents]] # Getting the top number of sentences from the ranked indexes for summarization\n",
        "\n",
        "    return ' '.join(SumofSents)\n",
        "\n",
        "# Input the text.....\n",
        "text_data = '''\n",
        "The Biden administration admitted Thursday that should not have posted a picture showing the faces of members of an elite U.S. Army Special Forces unit on assignment in Israel when it posted a photo of them in uniform shaking hands with the president.\n",
        "Apologizing for the mishap, a White House spokesperson told Fox News, \"As soon as this was brought to our attention, we immediately deleted the photo. We regret the error and any issues this may have caused.\n",
        "\"The photo was posted on the White House's Instagram account late Wednesday and included the faces of four special forces soldiers as they met Biden, who was on his high-profile trip to Israel at the time amid its ongoing war with Hamas.\n",
        "\"In Israel, President Biden met with firstresponders to thank them for their bravery and the work they're doing in response to the Hamas terrorist attacks,\" the caption below the photo read.\n",
        "The post received hundreds of thousands of views before finally being taken down about an hour later. The blunder illicited sharp criticism from Republicans with some blasting the White House as incompetent.\n",
        "The Republican National Committee's Alec Sears ridiculed the White House's blunder on X, formerly Twitter.\n",
        "\"So funny that the ‘Adults in charge’ are so on top of things they doxxed one of our most elite fighting forces in the midst of their deployment to the Middle East,\" Sears wrote.\n",
        "'''\n",
        "\n",
        "Summary = GenSum(text_data, NumofSents=2)  # Making a summary of the text with 2 sentences\n",
        "print(Summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMI2sryfBwUQ",
        "outputId": "1c4e717b-1e28-4991-c0e3-f735faa33b1f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The Biden administration admitted Thursday that should not have posted a picture showing the faces of members of an elite U.S. Army Special Forces unit on assignment in Israel when it posted a photo of them in uniform shaking hands with the president. \"The photo was posted on the White House's Instagram account late Wednesday and included the faces of four special forces soldiers as they met Biden, who was on his high-profile trip to Israel at the time amid its ongoing war with Hamas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YutgyLaYG8yL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IAAii9TOG8uu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}